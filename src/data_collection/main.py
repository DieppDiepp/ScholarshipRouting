# `main.py`

#   * **M·ª•c ƒë√≠ch:** File th·ª±c thi ch√≠nh c·ªßa b·∫°n.
#   * **N·ªôi dung:**
#     1.  T·∫£i c√°c bi·∫øn m√¥i tr∆∞·ªùng (`load_dotenv()`).
#     2.  T·∫£i danh s√°ch API keys t·ª´ `utils.api_key_loader.load_tavily_api_keys()`.
#     3.  T·∫£i danh s√°ch c√°c h·ªçc b·ªïng c·∫ßn t√¨m (v√≠ d·ª•: `["Chevening", "Fulbright"]`).
#     4.  T·∫£i c√°c h·∫±ng s·ªë t·ª´ `config.py`.
#     5.  Kh·ªüi t·∫°o `LangGraphSearchAgent` (ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a trong `agent/graph.py`), truy·ªÅn danh s√°ch API keys v√†o `__init__`.
#     6.  Ch·∫°y m·ªôt v√≤ng l·∫∑p `for` qua t·ª´ng h·ªçc b·ªïng, g·ªçi `agent.invoke()` cho m·ªói h·ªçc b·ªïng.
#     7.  H√†m `invoke` c·ªßa agent s·∫Ω t·ª± ƒë·ªông ch·∫°y to√†n b·ªô quy tr√¨nh l·∫∑p (research loop) v√† l∆∞u d·ªØ li·ªáu.

# data_collection/main.py

import os
import argparse # M·ªöI: Th√™m th∆∞ vi·ªán ƒë·ªÉ ƒë·ªçc tham s·ªë
import pandas as pd
from dotenv import load_dotenv
import json 
from typing import List, Dict, Any
# M·ªöI: Import ThreadPoolExecutor v√† helper
from concurrent.futures import ThreadPoolExecutor, as_completed
import time

# --- 1. X·ª¨ L√ù THAM S·ªê ƒê·∫¶U V√ÄO (ARGPARSE) ---
# Ph·∫£i th·ª±c hi·ªán vi·ªác n√†y TR∆Ø·ªöC TI√äN
parser = argparse.ArgumentParser(description="Ch·∫°y pipeline thu th·∫≠p th√¥ng tin h·ªçc b·ªïng.")
parser.add_argument(
    "--level", 
    type=str, 
    choices=["master", "bachelor", "phd"], 
    default="master",
    help="C·∫•p ƒë·ªô h·ªçc b·ªïng c·∫ßn x·ª≠ l√Ω (master, bachelor, or phd)."
)
args = parser.parse_args()

# --- 2. ƒê·∫∂T BI·∫æN M√îI TR∆Ø·ªúNG ---
# ƒê√¢y l√† b∆∞·ªõc quan tr·ªçng nh·∫•t. 
# ƒê·∫∑t bi·∫øn m√¥i tr∆∞·ªùng TR∆Ø·ªöC KHI import config.
os.environ["SCHOLARSHIP_LEVEL"] = args.level

# --- 3. IMPORT C√ÅC MODULE (SAU KHI ƒê√É ƒê·∫∂T ENV) ---
# Gi·ªù ƒë√¢y, khi c√°c file n√†y ƒë∆∞·ª£c import, ch√∫ng s·∫Ω ƒë·ªçc file config.py 
# v√† t·ª± ƒë·ªông l·∫•y ƒë√∫ng ƒë∆∞·ªùng d·∫´n d·ª±a tr√™n bi·∫øn "SCHOLARSHIP_LEVEL"
from utils.api_key_loader import load_tavily_api_keys, load_google_api_keys
from agent.tools import RotatingTavilyTool
from agent.graph import LangGraphSearchAgent, AgentState
import config # <--- config b√¢y gi·ªù ƒë√£ ƒë∆∞·ª£c "c·∫•u h√¨nh ƒë·ªông"
# S·ª¨A: Import h√†m l∆∞u tr·ªØ ƒë√£ ƒë·ªïi t√™n
from utils.data_logger import (
    save_draft_report_batch, 
    save_text_report, # H√†m n√†y v·∫´n l∆∞u 1-1, ch√∫ng ta s·∫Ω g·ªçi n√≥ t·ª´ main
    save_structured_report_batch,
    save_rag_batch
)

# --- C√ÄI ƒê·∫∂T BAN ƒê·∫¶U (Gi·ªØ nguy√™n) ---
env_path = os.path.join(os.path.dirname(__file__), '.env')
if not os.path.exists(env_path):
    env_path = os.path.join(os.path.dirname(__file__), '.env')
load_dotenv(dotenv_path=env_path)

# --- (H√ÄM WORKER CHO LU·ªíNG SONG SONG) ---
def run_single_scholarship(scholarship_name: str, tavily_keys: List[str], google_keys: List[str]) -> AgentState:
    """
    H√†m n√†y ƒë∆∞·ª£c ch·∫°y trong m·ªôt lu·ªìng (thread) ri√™ng bi·ªát.
    N√≥ kh·ªüi t·∫°o agent v√† ch·∫°y invoke cho 1 h·ªçc b·ªïng.
    N√ì KH√îNG GHI FILE.
    """
    print(f"  [Thread] üöÄ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω cho: {scholarship_name}")
    try:
        # M·ªói lu·ªìng ph·∫£i t·∫°o instance ri√™ng ƒë·ªÉ tr√°nh xung ƒë·ªôt
        tavily_tool = RotatingTavilyTool(api_keys=tavily_keys)
        agent = LangGraphSearchAgent(
            tool=tavily_tool,
            google_api_keys=google_keys
        )
        
        # Ch·∫°y agent
        final_state = agent.invoke(scholarship_name)
        print(f"  [Thread] ‚úÖ Ho√†n t·∫•t x·ª≠ l√Ω cho: {scholarship_name}")
        return final_state
    
    except Exception as e:
        print(f"  [Thread] ‚ùå L·ªñI khi x·ª≠ l√Ω '{scholarship_name}': {e}")
        # Tr·∫£ v·ªÅ m·ªôt state l·ªói ƒë·ªÉ main thread c√≥ th·ªÉ log
        return {
            "scholarship_name": scholarship_name,
            "error": str(e) 
        }

# --- (H√ÄM HELPER ƒê·ªÇ CHIA L√î) ---
def create_batches(data: list, batch_size: int):
    """Chia m·ªôt list th√†nh c√°c list nh·ªè (l√¥)."""
    for i in range(0, len(data), batch_size):
        yield data[i:i + batch_size]

# --- (H√ÄM MAIN M·ªöI) ---
def main():
    print(f"--- STARTING PIPELINE FOR LEVEL: {args.level.upper()} ---")
    
    try:
        tavily_api_keys = load_tavily_api_keys()
        google_api_keys = load_google_api_keys()
    except Exception as e:
        print(f"Error loading API keys: {e}")
        return

    try:
        print(f"Reading CSV file: {config.SCHOLARSHIP_DATA_PATH}")
        df = pd.read_csv(config.SCHOLARSHIP_DATA_PATH)
        all_scholarship_names = df[config.SCHOLARSHIP_NAME_COLUMN].dropna().unique().tolist()
    except Exception as e:
        print(f"Error reading CSV file: {e}")
        return
        
    # S·ª¨A: C·∫Øt (slice) danh s√°ch d·ª±a tr√™n config
    start = config.SCHOLARSHIP_START_INDEX
    end = config.SCHOLARSHIP_END_INDEX
    scholarships_to_run = all_scholarship_names[start:end]
    
    print(f"\nƒê√£ t√¨m th·∫•y {len(all_scholarship_names)} h·ªçc b·ªïng. S·∫Ω ch·∫°y {len(scholarships_to_run)} h·ªçc b·ªïng (t·ª´ index {start} ƒë·∫øn {end}).")
    print(f"S·∫Ω ch·∫°y song song v·ªõi {config.PARALLEL_WORKERS} lu·ªìng, k√≠ch th∆∞·ªõc l√¥ {config.PARALLEL_WORKERS}.")

    start_time = time.time()
    
    # T·∫°o c√°c l√¥
    batches = list(create_batches(scholarships_to_run, config.PARALLEL_WORKERS))
    
    for i, batch_names in enumerate(batches):
        print(f"\n=============================================")
        print(f"üöÄ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω L√¥ {i+1}/{len(batches)} (g·ªìm {len(batch_names)} h·ªçc b·ªïng)...")
        
        batch_results: List[AgentState] = []
        
        # T·∫°o ThreadPoolExecutor
        with ThreadPoolExecutor(max_workers=config.PARALLEL_WORKERS) as executor:
            # G·ª≠i c√°c t√°c v·ª• v√†o pool
            futures = {
                executor.submit(
                    run_single_scholarship, 
                    name, 
                    tavily_api_keys, 
                    google_api_keys
                ): name for name in batch_names
            }
            
            # Thu th·∫≠p k·∫øt qu·∫£ khi ch√∫ng ho√†n th√†nh
            for future in as_completed(futures):
                result_state = future.result()
                batch_results.append(result_state)

        print(f"\n--- L√¥ {i+1} ho√†n t·∫•t. B·∫Øt ƒë·∫ßu ghi d·ªØ li·ªáu... ---")
        
        # --- GHI D·ªÆ LI·ªÜU (CH·∫†Y TR√äN MAIN THREAD) ---
        
        # L·ªçc ra c√°c state th√†nh c√¥ng
        successful_states = [s for s in batch_results if "error" not in s]
        failed_states = [s for s in batch_results if "error" in s]

        if successful_states:
            # 1. Ghi v√†o RAG DB (append .jsonl)
            save_rag_batch(successful_states, config.RAG_DATABASE_PATH)
            
            # 2. Ghi b√°o c√°o nh√°p (debug)
            save_draft_report_batch(successful_states, config.DRAFT_REPORTS_PATH)
            
            # 3. Ghi b√°o c√°o vƒÉn b·∫£n
            for state in successful_states:
                save_text_report(
                    state["scholarship_name"], 
                    state.get("synthesis_report_text", "Error: No text report generated"), 
                    config.FINAL_TEXT_REPORTS_PATH
                )
            
            # 4. Ghi b√°o c√°o c·∫•u tr√∫c cu·ªëi c√πng
            save_structured_report_batch(successful_states, config.STRUCTURED_ENGLISH_REPORTS_PATH)
        
        if failed_states:
            print(f"‚ùå C·∫£nh b√°o: {len(failed_states)} h·ªçc b·ªïng trong l√¥ th·∫•t b·∫°i:")
            for state in failed_states:
                print(f"  - {state['scholarship_name']}: {state['error']}")

    end_time = time.time()
    print("\n=============================================")
    print(f"--- TO√ÄN B·ªò PIPELINE HO√ÄN T·∫§T TRONG {end_time - start_time:.2f} GI√ÇY ---")
    print(f"Ki·ªÉm tra file RAG DB: {config.RAG_DATABASE_PATH}")
    print(f"Ki·ªÉm tra file B√°o C√°o Nh√°p: {config.DRAFT_REPORTS_PATH}")
    print(f"Ki·ªÉm tra file B√°o C√°o VƒÉn B·∫£n: {config.FINAL_TEXT_REPORTS_PATH}")
    print(f"Ki·ªÉm tra file B√°o C√°o C·∫•u Tr√∫c: {config.STRUCTURED_ENGLISH_REPORTS_PATH}")

if __name__ == "__main__":
    main()