# ### \#\#\# `agent/nodes.py`

#   * **Má»¥c Ä‘Ã­ch:** Chá»©a code thá»±c thi cho tá»«ng node trong graph.
#   * **Ná»™i dung:**
#       * `def initial_search_node(state: AgentState) -> Dict:`
#           * Láº¥y `scholarship_name` tá»« `state`.
#           * Gá»i `TavilyTool` (tá»« `agent.tools`) vá»›i **prompt ban Ä‘áº§u** (tá»« `prompts.initial_search`).
#           * Tráº£ vá» `{"context_documents": ..., "visited_urls": ...}` Ä‘á»ƒ cáº­p nháº­t state.
#       * `def analyze_and_plan_node(state: AgentState) -> Dict:`
#           * ÄÃ¢y lÃ  "bá»™ nÃ£o" ğŸ§ .
#           * Láº¥y `context_documents` (ná»™i dung web thÃ´) tá»« `state`.
#           * Gá»i má»™t LLM (vÃ­ dá»¥: Gemini) vá»›i **prompt "Plan & Analyze"** (tá»« `prompts.plan_and_analyze`).
#           * LLM sáº½ Ä‘á»c ná»™i dung vÃ  tráº£ vá»: 1) Dá»¯ liá»‡u Ä‘Ã£ tÃ¬m tháº¥y, vÃ  2) **Danh sÃ¡ch cÃ¡c truy váº¥n má»›i** cho thÃ´ng tin cÃ²n thiáº¿u.
#           * Tráº£ vá» `{"missing_information": ..., "final_report": ...}` (cáº­p nháº­t bÃ¡o cÃ¡o vá»›i nhá»¯ng gÃ¬ Ä‘Ã£ tÃ¬m tháº¥y).
#       * `def drill_down_search_node(state: AgentState) -> Dict:`
#           * Láº¥y danh sÃ¡ch `missing_information` (cÃ¡c truy váº¥n) tá»« `state`.
#           * Náº¿u danh sÃ¡ch rá»—ng, bá» qua.
#           * Náº¿u cÃ³ truy váº¥n, cháº¡y `RunnableParallel` Ä‘á»ƒ tÃ¬m kiáº¿m song song cÃ¡c truy váº¥n nÃ y.
#           * Tráº£ vá» `{"context_documents": ...}` (ná»™i dung má»›i tÃ¬m Ä‘Æ°á»£c) Ä‘á»ƒ *thÃªm* vÃ o state.
#       * `def final_synthesis_node(state: AgentState) -> Dict:`
#           * Láº¥y *toÃ n bá»™* `context_documents` tá»« state.
#           * Gá»i LLM vá»›i **prompt "Synthesis"** (tá»« `prompts.synthesis`) Ä‘á»ƒ táº¡o bÃ¡o cÃ¡o cuá»‘i cÃ¹ng.
#           * Tráº£ vá» `{"final_report": ...}`.

# data_collection/agent/nodes.py

import os
import json
from typing import Dict, Any, List
# Sá»¬A: Import LLM class Ä‘á»ƒ dÃ¹ng lÃ m type hint
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.output_parsers import JsonOutputParser

from agent.state import AgentState 
from agent.tools import RotatingTavilyTool
# ... (import cÃ¡c prompts) ...
from prompts.initial_search import INITIAL_SEARCH_PROMPT
from prompts.plan_and_analyze import analyze_prompt
from prompts.synthesis import synthesis_prompt 
from prompts.structuring import structuring_prompt

from utils.data_logger import save_to_rag_db
import config

# --- Node 1: TÃ¬m Kiáº¿m Ban Äáº§u (KhÃ´ng thay Ä‘á»•i) ---
def initial_search_node(state: AgentState, tool: RotatingTavilyTool) -> Dict[str, Any]:
    # (Ná»™i dung hÃ m giá»¯ nguyÃªn)
    print(f"\n--- Node: Initial Search (Loop {state['current_loop']}) ---")
    scholarship_name = state["scholarship_name"]
    query = INITIAL_SEARCH_PROMPT.format(scholarship_name=scholarship_name)
    print(f"  Äang tÃ¬m kiáº¿m: '{query}'")
    results = tool.invoke(query, max_results=5)
    valid_results = [res for res in results if res.get("content")]
    print(f"  -> TÃ¬m tháº¥y {len(valid_results)} káº¿t quáº£ há»£p lá»‡.")
    save_to_rag_db(scholarship_name, valid_results, config.RAG_DATABASE_PATH)
    new_urls = {res.get("url") for res in valid_results}
    
    return {
        "context_documents": valid_results,
        "visited_urls": new_urls,
        "api_call_count": state["api_call_count"] + 1,
        "current_loop": state["current_loop"] + 1,
        "failed_queries": set(),
        "queries_just_ran": [query] 
    }

# --- Node 2: PhÃ¢n TÃ­ch & Láº­p Káº¿ Hoáº¡ch (Cáº­p nháº­t) ---
def analyze_and_plan_node(state: AgentState, llm: ChatGoogleGenerativeAI) -> Dict[str, Any]:
    print(f"\n--- Node: Analyze & Plan (Loop {state['current_loop']}) ---")
    scholarship_name = state["scholarship_name"]
    
    context_str = "\n\n---\n\n".join(
        [f"URL: {doc['url']}\nCONTENT: {doc['content']}" for doc in state["context_documents"]]
    )
    failed_queries_str = "\n".join(state["failed_queries"])
    
    # # Sá»¬A: Sá»­ dá»¥ng biáº¿n tá»« file config
    # llm = ChatGoogleGenerativeAI(
    #     model=config.NON_CREATIVE_LLM_MODEL,
    #     temperature=config.NON_CREATIVE_LLM_TEMP,
    #     google_api_key=os.environ.get("GOOGLE_API_KEY")
    # )
    
    analysis_chain = analyze_prompt | llm | JsonOutputParser()
    print("  Äang gá»i LLM Ä‘á»ƒ phÃ¢n tÃ­ch vÃ  láº­p káº¿ hoáº¡ch...")
    
    try:
        response = analysis_chain.invoke({
            "scholarship_name": scholarship_name,
            "context": context_str,
            "failed_queries": failed_queries_str
        })
        
        print("  -> LLM phÃ¢n tÃ­ch hoÃ n táº¥t.")
        
        queries_we_just_ran = state.get("queries_just_ran", [])
        current_failed_queries = state.get("failed_queries", set())
        llm_missing_queries = response.get("missing_queries", [])
        truly_missing_queries = []
        
        for q in llm_missing_queries:
            if q in queries_we_just_ran:
                print(f"    -> PhÃ¡t hiá»‡n truy váº¥n tháº¥t báº¡i (láº·p láº¡i): '{q}'")
                current_failed_queries.add(q) 
            elif q not in current_failed_queries:
                truly_missing_queries.append(q)
                
        print(f"  -> Truy váº¥n LLM Ä‘á» xuáº¥t: {len(llm_missing_queries)}.")
        print(f"  -> Truy váº¥n THá»°C Sá»° cÃ²n thiáº¿u (sau khi lá»c): {len(truly_missing_queries)}.")
        
        return {
            "final_report": response.get("report_data"),
            "missing_information": truly_missing_queries,
            "failed_queries": current_failed_queries,
            "queries_just_ran": []
        }
    except Exception as e:
        print(f"  Lá»—i khi gá»i LLM hoáº·c parse JSON: {e}")
        return {"missing_information": [], "queries_just_ran": []}

# --- Node 3: TÃ¬m Kiáº¿m ChuyÃªn SÃ¢u (Cáº­p nháº­t) ---
def drill_down_search_node(state: AgentState, tool: RotatingTavilyTool) -> Dict[str, Any]:
    print(f"\n--- Node: Drill-Down Search (Loop {state['current_loop']}) ---")
    scholarship_name = state["scholarship_name"]
    queries = state["missing_information"]
    
    current_docs = state["context_documents"]
    current_urls = state["visited_urls"]
    
    new_docs = []
    
    # Sá»¬A: Sá»­ dá»¥ng biáº¿n tá»« file config
    queries_to_run = queries[:config.DRILL_DOWN_QUERY_COUNT] 
    
    print(f"  Sáº½ thá»±c thi {len(queries_to_run)}/{len(queries)} truy váº¥n cÃ²n thiáº¿u.")
    
    api_calls_made = 0
    for query in queries_to_run:
        if state["api_call_count"] + api_calls_made >= config.MAX_API_CALLS_PER_SCHOLARSHIP:
            print("  -> ÄÃ£ Ä‘áº¡t giá»›i háº¡n API call, dá»«ng tÃ¬m kiáº¿m chuyÃªn sÃ¢u.")
            break
            
        print(f"  Äang tÃ¬m kiáº¿m: '{query}'")
        results = tool.invoke(query, max_results=2)
        api_calls_made += 1
        
        for res in results:
            if res.get("url") not in current_urls and res.get("content"):
                new_docs.append(res)
                current_urls.add(res.get("url"))
    
    print(f"  -> TÃ¬m tháº¥y {len(new_docs)} tÃ i liá»‡u má»›i.")
    if new_docs:
        save_to_rag_db(scholarship_name, new_docs, config.RAG_DATABASE_PATH)
    
    return {
        "context_documents": current_docs + new_docs,
        "visited_urls": current_urls,
        "missing_information": queries[len(queries_to_run):],
        "api_call_count": state["api_call_count"] + api_calls_made,
        "current_loop": state["current_loop"] + 1,
        "queries_just_ran": queries_to_run
    }

# --- Node 4: Tá»•ng Há»£p Cuá»‘i CÃ¹ng (Cáº­p nháº­t) ---
def final_synthesis_node(state: AgentState, llm: ChatGoogleGenerativeAI) -> Dict[str, Any]:
    print(f"\n--- Node: Final Synthesis ---")
    
    context_str = "\n\n---\n\n".join(
        [f"URL: {doc['url']}\nCONTENT: {doc['content']}" for doc in state["context_documents"]]
    )
    draft_report_str = json.dumps(state["final_report"], indent=2, ensure_ascii=False)
    
    # # Sá»¬A: Sá»­ dá»¥ng biáº¿n tá»« file config
    # llm = ChatGoogleGenerativeAI(
    #     model=config.NON_CREATIVE_LLM_MODEL,
    #     temperature=config.NON_CREATIVE_LLM_TEMP,
    #     google_api_key=os.environ.get("GOOGLE_API_KEY")
    # )
    
    synthesis_chain = synthesis_prompt | llm | JsonOutputParser() 
    
    print("  Äang gá»i LLM Ä‘á»ƒ tá»•ng há»£p bÃ¡o cÃ¡o cuá»‘i cÃ¹ng...")
    
    try:
        final_report = synthesis_chain.invoke({
            "scholarship_name": state["scholarship_name"],
            "context": context_str,
            "draft_report": draft_report_str
        })
        print("  -> Tá»•ng há»£p hoÃ n táº¥t.")
        return {"final_report": final_report}
    except Exception as e:
        print(f"  Lá»—i khi tá»•ng há»£p cuá»‘i cÃ¹ng: {e}")
        return {"final_report": state["final_report"]}
    
# --- Node 5: Cáº¥u TrÃºc (Sá»¬A TÃŠN VÃ€ LOG) ---
def structure_node(state: AgentState, llm: ChatGoogleGenerativeAI) -> Dict[str, Any]:
    """
    Node cuá»‘i cÃ¹ng: Chuyá»ƒn Ä‘á»•i bÃ¡o cÃ¡o JSON 10 má»¥c (tiáº¿ng Anh)
    thÃ nh má»™t JSON pháº³ng (flat) tiáº¿ng Anh.
    """
    print(f"\n--- Node: Structure Report ---") # Äá»•i tÃªn log

    final_report_json = state["final_report"]
    final_report_str = json.dumps(final_report_json, indent=2, ensure_ascii=False)

    # llm = ChatGoogleGenerativeAI(
    #     model=config.NON_CREATIVE_LLM_MODEL,
    #     temperature=config.NON_CREATIVE_LLM_TEMP,
    #     google_api_key=os.environ.get("GOOGLE_API_KEY")
    # )

    structuring_chain = structuring_prompt | llm | JsonOutputParser()

    print("  Äang gá»i LLM Ä‘á»ƒ cáº¥u trÃºc láº¡i bÃ¡o cÃ¡o...") # Äá»•i log

    try:
        structured_report = structuring_chain.invoke({
            "final_report": final_report_str
        })

        # Äáº£m báº£o Scholarship_Name lÃ  tÃªn gá»‘c
        structured_report["Scholarship_Name"] = state["scholarship_name"]

        print("  -> Cáº¥u trÃºc bÃ¡o cÃ¡o hoÃ n táº¥t.") # Äá»•i log
        return {"structured_report": structured_report}

    except Exception as e:
        print(f"  Lá»—i khi cáº¥u trÃºc bÃ¡o cÃ¡o: {e}") # Äá»•i log
        return {"structured_report": {}}