# ### \#\#\# `agent/nodes.py`

#   * **Mр╗Цc ─Љ├Гch:** Chр╗Еa code thр╗▒c thi cho tр╗Фng node trong graph.
#   * **Nр╗Ўi dung:**
#       * `def initial_search_node(state: AgentState) -> Dict:`
#           * Lр║Цy `scholarship_name` tр╗Ф `state`.
#           * Gр╗Їi `TavilyTool` (tр╗Ф `agent.tools`) vр╗Џi **prompt ban ─Љр║Дu** (tр╗Ф `prompts.initial_search`).
#           * Trр║Б vр╗Ђ `{"context_documents": ..., "visited_urls": ...}` ─Љр╗Ѓ cр║Гp nhр║Гt state.
#       * `def analyze_and_plan_node(state: AgentState) -> Dict:`
#           * ─љ├бy l├а "bр╗Ў n├Бo" ­ЪДа.
#           * Lр║Цy `context_documents` (nр╗Ўi dung web th├┤) tр╗Ф `state`.
#           * Gр╗Їi mр╗Ўt LLM (v├Г dр╗Ц: Gemini) vр╗Џi **prompt "Plan & Analyze"** (tр╗Ф `prompts.plan_and_analyze`).
#           * LLM sр║й ─Љр╗Їc nр╗Ўi dung v├а trр║Б vр╗Ђ: 1) Dр╗» liр╗Єu ─Љ├Б t├гm thр║Цy, v├а 2) **Danh s├Аch c├Аc truy vр║Цn mр╗Џi** cho th├┤ng tin c├▓n thiр║┐u.
#           * Trр║Б vр╗Ђ `{"missing_information": ..., "final_report": ...}` (cр║Гp nhр║Гt b├Аo c├Аo vр╗Џi nhр╗»ng g├г ─Љ├Б t├гm thр║Цy).
#       * `def drill_down_search_node(state: AgentState) -> Dict:`
#           * Lр║Цy danh s├Аch `missing_information` (c├Аc truy vр║Цn) tр╗Ф `state`.
#           * Nр║┐u danh s├Аch rр╗Ќng, bр╗Ј qua.
#           * Nр║┐u c├│ truy vр║Цn, chр║Аy `RunnableParallel` ─Љр╗Ѓ t├гm kiр║┐m song song c├Аc truy vр║Цn n├аy.
#           * Trр║Б vр╗Ђ `{"context_documents": ...}` (nр╗Ўi dung mр╗Џi t├гm ─Љк░р╗Бc) ─Љр╗Ѓ *th├фm* v├аo state.
#       * `def final_synthesis_node(state: AgentState) -> Dict:`
#           * Lр║Цy *to├аn bр╗Ў* `context_documents` tр╗Ф state.
#           * Gр╗Їi LLM vр╗Џi **prompt "Synthesis"** (tр╗Ф `prompts.synthesis`) ─Љр╗Ѓ tр║Аo b├Аo c├Аo cuр╗Љi c├╣ng.
#           * Trр║Б vр╗Ђ `{"final_report": ...}`.

# data_collection/agent/nodes.py

import os
import json
from typing import Dict, Any, List
# Sр╗гA: Import LLM class ─Љр╗Ѓ d├╣ng l├аm type hint
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.output_parsers import JsonOutputParser

from agent.state import AgentState 
from agent.tools import RotatingTavilyTool
# ... (import c├Аc prompts) ...
from prompts.initial_search import INITIAL_SEARCH_PROMPT
from prompts.plan_and_analyze import analyze_prompt
from prompts.synthesis import synthesis_prompt 
from prompts.structuring import structuring_prompt

from utils.data_logger import save_to_rag_db
import config

# --- Node 1: T├гm Kiр║┐m Ban ─љр║Дu (Kh├┤ng thay ─Љр╗Ћi) ---
def initial_search_node(state: AgentState, tool: RotatingTavilyTool) -> Dict[str, Any]:
    # (Nр╗Ўi dung h├аm giр╗» nguy├фn)
    print(f"\n--- Node: Initial Search (Loop {state['current_loop']}) ---")
    scholarship_name = state["scholarship_name"]
    query = INITIAL_SEARCH_PROMPT.format(scholarship_name=scholarship_name)
    print(f"  ─љang t├гm kiр║┐m: '{query}'")
    results = tool.invoke(query, max_results=5)
    valid_results = [res for res in results if res.get("content")]
    print(f"  -> T├гm thр║Цy {len(valid_results)} kр║┐t quр║Б hр╗Бp lр╗Є.")
    save_to_rag_db(scholarship_name, valid_results, config.RAG_DATABASE_PATH)
    new_urls = {res.get("url") for res in valid_results}
    
    return {
        "context_documents": valid_results,
        "visited_urls": new_urls,
        "api_call_count": state["api_call_count"] + 1,
        "current_loop": state["current_loop"] + 1,
        "failed_queries": set(),
        "queries_just_ran": [query] 
    }

# --- Node 2: Ph├бn T├Гch & Lр║Гp Kр║┐ Hoр║Аch (Cр║Гp nhр║Гt) ---
def analyze_and_plan_node(state: AgentState, llm: ChatGoogleGenerativeAI) -> Dict[str, Any]:
    print(f"\n--- Node: Analyze & Plan (Loop {state['current_loop']}) ---")
    scholarship_name = state["scholarship_name"]
    
    context_str = "\n\n---\n\n".join(
        [f"URL: {doc['url']}\nCONTENT: {doc['content']}" for doc in state["context_documents"]]
    )
    failed_queries_str = "\n".join(state["failed_queries"])
    
    # # Sр╗гA: Sр╗Г dр╗Цng biр║┐n tр╗Ф file config
    # llm = ChatGoogleGenerativeAI(
    #     model=config.NON_CREATIVE_LLM_MODEL,
    #     temperature=config.NON_CREATIVE_LLM_TEMP,
    #     google_api_key=os.environ.get("GOOGLE_API_KEY")
    # )
    
    analysis_chain = analyze_prompt | llm | JsonOutputParser()
    print("  ─љang gр╗Їi LLM ─Љр╗Ѓ ph├бn t├Гch v├а lр║Гp kр║┐ hoр║Аch...")
    
    try:
        response = analysis_chain.invoke({
            "scholarship_name": scholarship_name,
            "context": context_str,
            "failed_queries": failed_queries_str
        })
        
        print("  -> LLM ph├бn t├Гch ho├аn tр║Цt.")
        
        queries_we_just_ran = state.get("queries_just_ran", [])
        current_failed_queries = state.get("failed_queries", set())
        llm_missing_queries = response.get("missing_queries", [])
        truly_missing_queries = []
        
        for q in llm_missing_queries:
            if q in queries_we_just_ran:
                print(f"    -> Ph├Аt hiр╗Єn truy vр║Цn thр║Цt bр║Аi (lр║иp lр║Аi): '{q}'")
                current_failed_queries.add(q) 
            elif q not in current_failed_queries:
                truly_missing_queries.append(q)
                
        print(f"  -> Truy vр║Цn LLM ─Љр╗Ђ xuр║Цt: {len(llm_missing_queries)}.")
        print(f"  -> Truy vр║Цn THр╗░C Sр╗░ c├▓n thiр║┐u (sau khi lр╗Їc): {len(truly_missing_queries)}.")
        
        return {
            "final_report": response.get("report_data"),
            "missing_information": truly_missing_queries,
            "failed_queries": current_failed_queries,
            "queries_just_ran": []
        }
    except Exception as e:
        print(f"  Lр╗Ќi khi gр╗Їi LLM hoр║иc parse JSON: {e}")
        return {"missing_information": [], "queries_just_ran": []}

# --- Node 3: T├гm Kiр║┐m Chuy├фn S├бu (Cр║Гp nhр║Гt) ---
def drill_down_search_node(state: AgentState, tool: RotatingTavilyTool) -> Dict[str, Any]:
    print(f"\n--- Node: Drill-Down Search (Loop {state['current_loop']}) ---")
    scholarship_name = state["scholarship_name"]
    queries = state["missing_information"]
    
    current_docs = state["context_documents"]
    current_urls = state["visited_urls"]
    
    new_docs = []
    
    # Sр╗гA: Sр╗Г dр╗Цng biр║┐n tр╗Ф file config
    queries_to_run = queries[:config.DRILL_DOWN_QUERY_COUNT] 
    
    print(f"  Sр║й thр╗▒c thi {len(queries_to_run)}/{len(queries)} truy vр║Цn c├▓n thiр║┐u.")
    
    api_calls_made = 0
    for query in queries_to_run:
        if state["api_call_count"] + api_calls_made >= config.MAX_API_CALLS_PER_SCHOLARSHIP:
            print("  -> ─љ├Б ─Љр║Аt giр╗Џi hр║Аn API call, dр╗Фng t├гm kiр║┐m chuy├фn s├бu.")
            break
            
        print(f"  ─љang t├гm kiр║┐m: '{query}'")
        results = tool.invoke(query, max_results=2)
        api_calls_made += 1
        
        for res in results:
            if res.get("url") not in current_urls and res.get("content"):
                new_docs.append(res)
                current_urls.add(res.get("url"))
    
    print(f"  -> T├гm thр║Цy {len(new_docs)} t├аi liр╗Єu mр╗Џi.")
    if new_docs:
        save_to_rag_db(scholarship_name, new_docs, config.RAG_DATABASE_PATH)
    
    return {
        "context_documents": current_docs + new_docs,
        "visited_urls": current_urls,
        "missing_information": queries[len(queries_to_run):],
        "api_call_count": state["api_call_count"] + api_calls_made,
        "current_loop": state["current_loop"] + 1,
        "queries_just_ran": queries_to_run
    }

# --- Node 4: Tр╗Ћng Hр╗Бp Cuр╗Љi C├╣ng (Cр║Гp nhр║Гt) ---
def final_synthesis_node(state: AgentState, llm: ChatGoogleGenerativeAI) -> Dict[str, Any]:
    print(f"\n--- Node: Final Synthesis ---")
    
    context_str = "\n\n---\n\n".join(
        [f"URL: {doc['url']}\nCONTENT: {doc['content']}" for doc in state["context_documents"]]
    )
    draft_report_str = json.dumps(state["final_report"], indent=2, ensure_ascii=False)
    
    # # Sр╗гA: Sр╗Г dр╗Цng biр║┐n tр╗Ф file config
    # llm = ChatGoogleGenerativeAI(
    #     model=config.NON_CREATIVE_LLM_MODEL,
    #     temperature=config.NON_CREATIVE_LLM_TEMP,
    #     google_api_key=os.environ.get("GOOGLE_API_KEY")
    # )
    
    synthesis_chain = synthesis_prompt | llm | JsonOutputParser() 
    
    print("  ─љang gр╗Їi LLM ─Љр╗Ѓ tр╗Ћng hр╗Бp b├Аo c├Аo cuр╗Љi c├╣ng...")
    
    try:
        final_report = synthesis_chain.invoke({
            "scholarship_name": state["scholarship_name"],
            "context": context_str,
            "draft_report": draft_report_str
        })
        print("  -> Tр╗Ћng hр╗Бp ho├аn tр║Цt.")
        return {"final_report": final_report}
    except Exception as e:
        print(f"  Lр╗Ќi khi tр╗Ћng hр╗Бp cuр╗Љi c├╣ng: {e}")
        return {"final_report": state["final_report"]}
    
# --- Node 5: Cр║Цu Tr├║c (Sр╗гA T├іN V├ђ LOG) ---
def structure_node(state: AgentState, llm: ChatGoogleGenerativeAI) -> Dict[str, Any]:
    """
    Node cuр╗Љi c├╣ng: Chuyр╗Ѓn ─Љр╗Ћi b├Аo c├Аo JSON 10 mр╗Цc (tiр║┐ng Anh)
    th├аnh mр╗Ўt JSON phр║│ng (flat) tiр║┐ng Anh.
    """
    print(f"\n--- Node: Structure Report ---") # ─љр╗Ћi t├фn log

    final_report_json = state["final_report"]
    final_report_str = json.dumps(final_report_json, indent=2, ensure_ascii=False)

    # llm = ChatGoogleGenerativeAI(
    #     model=config.NON_CREATIVE_LLM_MODEL,
    #     temperature=config.NON_CREATIVE_LLM_TEMP,
    #     google_api_key=os.environ.get("GOOGLE_API_KEY")
    # )

    structuring_chain = structuring_prompt | llm | JsonOutputParser()

    print("  ─љang gр╗Їi LLM ─Љр╗Ѓ cр║Цu tr├║c lр║Аi b├Аo c├Аo...") # ─љр╗Ћi log

    try:
        structured_report = structuring_chain.invoke({
            "final_report": final_report_str
        })

        # ─љр║Бm bр║Бo Scholarship_Name l├а t├фn gр╗Љc
        structured_report["Scholarship_Name"] = state["scholarship_name"]

        print("  -> Cр║Цu tr├║c b├Аo c├Аo ho├аn tр║Цt.") # ─љр╗Ћi log
        return {"structured_report": structured_report}

    except Exception as e:
        print(f"  Lр╗Ќi khi cр║Цu tr├║c b├Аo c├Аo: {e}") # ─љр╗Ћi log
        return {"structured_report": {}}