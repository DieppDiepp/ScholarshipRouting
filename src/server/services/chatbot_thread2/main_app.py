import warnings
import logging
from services.auth_svc import get_profile

# L·∫•y logger cho file n√†y
logger = logging.getLogger(__name__)

from .rag_pipeline.translator import translate_query_to_english
from .rag_pipeline.query_extractor import extract_filters
from .rag_pipeline.retriever import search_scholarships
from .rag_pipeline.generator import generate_answer
# --- IMPORT M·ªöI: QUERY ROUTER ---
from .rag_pipeline.query_router import classify_query, should_use_rag, get_direct_response
from . import config

# --- H√†m helper ƒë·ªÉ format l·ªãch s·ª≠ ---
def format_chat_history(user_id: str, limit: int = 6) -> str:
    """
    L·∫•y l·ªãch s·ª≠ chat t·ª´ Firestore v√† format th√†nh chu·ªói string.
    Kh·ªõp v·ªõi c·∫•u tr√∫c d·ªØ li·ªáu trong crm_svc: 
    Key: 'chatHistory'
    Item: { 'query': '...', 'answer': '...', 'timestamp': ... }
    """
    if not user_id:
        return "No history available."

    try:
        user_profile = get_profile(user_id)
        
        if not user_profile:
            return "No history available."
        
        history_list = user_profile.get("chatHistory", [])
        
        if not history_list:
            return "No history available."

        # L·∫•y n tin nh·∫Øn cu·ªëi c√πng
        # L∆∞u √Ω: logic l∆∞u l√† append, n√™n tin m·ªõi nh·∫•t ·ªü cu·ªëi list.
        recent_history = history_list[-limit:]
        
        formatted_str = ""
        for chat_item in recent_history:
            user_text = chat_item.get("query", "")
            ai_text = chat_item.get("answer", "")
            
            if user_text:
                formatted_str += f"User: {user_text}\n"
            if ai_text:
                formatted_str += f"AI: {ai_text}\n"
        
        # Log ra ƒë·ªÉ debug xem ƒë√£ l·∫•y ƒë∆∞·ª£c ch∆∞a
        logger.info(f"Formatted {len(recent_history)} history items for user {user_id}")
        
        return formatted_str

    except Exception as e:
        logger.error(f"Error fetching chat history for user {user_id}: {e}")
        return "Error fetching history."
    
# --- C·∫≠p nh·∫≠t h√†m ask_chatbot ---
def ask_chatbot(query: str, user_id: str = None):
    """
    Ch·∫°y pipeline RAG c√≥ t√≠ch h·ª£p l·ªãch s·ª≠ chat V√Ä QUERY ROUTER.
    
    Flow:
    1. Router ph√¢n lo·∫°i query
    2. N·∫øu l√† greeting/chitchat/off_topic ‚Üí Tr·∫£ l·ªùi tr·ª±c ti·∫øp (NHANH)
    3. N·∫øu l√† scholarship_search ‚Üí Ch·∫°y full RAG pipeline
    """
    logger.info(f"========= Query M·ªõi =========\nUser ID: {user_id}\nQuery G·ªëc: {query}\n")
    
    # --- B∆Ø·ªöC 0: QUERY ROUTING (M·ªöI) ---
    logger.info("[PHASE 0] Query Classification & Routing")
    classification = classify_query(query)
    
    # N·∫øu KH√îNG c·∫ßn RAG ‚Üí Tr·∫£ l·ªùi tr·ª±c ti·∫øp
    if not should_use_rag(classification):
        logger.info(f"--- Query type '{classification.query_type}' kh√¥ng c·∫ßn RAG. Tr·∫£ l·ªùi tr·ª±c ti·∫øp. ---")
        direct_answer = get_direct_response(classification, query)
        
        # Tr·∫£ v·ªÅ format gi·ªëng ScholarshipAnswer ƒë·ªÉ ƒë·ªìng nh·∫•t
        return config.ScholarshipAnswer(
            scholarship_names=[],
            answer=direct_answer
        )
    
    # --- N·∫æU C·∫¶N RAG, CH·∫†Y PIPELINE B√åNH TH∆Ø·ªúNG ---
    logger.info("--- Query c·∫ßn RAG. Ch·∫°y full pipeline... ---")
    
    # 1. L·∫•y v√† format l·ªãch s·ª≠ chat
    chat_history_str = format_chat_history(user_id)
    logger.info(f"Chat History Context:\n{chat_history_str}")

    # 2. Translate
    english_query = translate_query_to_english(query)
    
    # 3. Extract
    filters = extract_filters(english_query)
    logger.info(f"\n[PHASE 2] Extracted Filters:\n{filters.model_dump_json(indent=2, exclude_none=True)}")
    
    # 4. Retrieve
    retrieved_docs = search_scholarships(english_query, filters)
    
    # 5. Generate (Truy·ªÅn th√™m history)
    final_answer_obj = generate_answer(query, retrieved_docs, chat_history_str)
    
    # --- K·∫æT QU·∫¢ ---
    logger.info("\n--- ü§ñ Chatbot Tr·∫£ l·ªùi ---")
    logger.info(final_answer_obj.answer)
    logger.info("\n--- üîë T√™n h·ªçc b·ªïng ---")
    logger.info(f"{final_answer_obj.scholarship_names}") 
    logger.info("\n===============================")
    
    # Tr·∫£ v·ªÅ object ƒë·ªÉ Route s·ª≠ d·ª•ng
    return final_answer_obj

if __name__ == "__main__":
    warnings.filterwarnings("ignore")
    
    # --- Test Case 1 (Ti·∫øng Vi·ªát) ---
    query1 = "T√¥i mu·ªën t√¨m h·ªçc b·ªïng to√†n ph·∫ßn th·∫°c sƒ© ng√†nh khoa h·ªçc d·ªØ li·ªáu ·ªü ch√¢u √¢u, t√¥i c√≥ gpa cao v√† k·ªπ nƒÉng l√£nh ƒë·∫°o t·ªët"
    ask_chatbot(query1)
    
    # --- Test Case 2 (Ti·∫øng Anh) ---
    query2 = "I want to find a full scholarship for a Master‚Äôs program in Data Science in Europe. I have a high GPA and strong leadership skills."
    ask_chatbot(query2)

    # --- (TH√äM D√íNG N√ÄY) ---
    # B·∫£o b·ªô ƒë·ªám x·∫£ log v√†o file tr∆∞·ªõc khi script tho√°t.
    logging.shutdown()