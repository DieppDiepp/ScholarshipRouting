import warnings
import logging
from services.auth_svc import get_profile

# L·∫•y logger cho file n√†y
logger = logging.getLogger(__name__)

from .rag_pipeline.translator import translate_query_to_english
from .rag_pipeline.query_extractor import extract_filters
from .rag_pipeline.retriever import search_scholarships
from .rag_pipeline.generator import generate_answer

# --- H√†m helper ƒë·ªÉ format l·ªãch s·ª≠ ---
def format_chat_history(user_id: str, limit: int = 6) -> str:
    """
    L·∫•y l·ªãch s·ª≠ chat t·ª´ Firestore v√† format th√†nh chu·ªói string.
    Kh·ªõp v·ªõi c·∫•u tr√∫c d·ªØ li·ªáu trong crm_svc: 
    Key: 'chatHistory'
    Item: { 'query': '...', 'answer': '...', 'timestamp': ... }
    """
    if not user_id:
        return "No history available."

    try:
        user_profile = get_profile(user_id)
        
        if not user_profile:
            return "No history available."
        
        history_list = user_profile.get("chatHistory", [])
        
        if not history_list:
            return "No history available."

        # L·∫•y n tin nh·∫Øn cu·ªëi c√πng
        # L∆∞u √Ω: logic l∆∞u l√† append, n√™n tin m·ªõi nh·∫•t ·ªü cu·ªëi list.
        recent_history = history_list[-limit:]
        
        formatted_str = ""
        for chat_item in recent_history:
            user_text = chat_item.get("query", "")
            ai_text = chat_item.get("answer", "")
            
            if user_text:
                formatted_str += f"User: {user_text}\n"
            if ai_text:
                formatted_str += f"AI: {ai_text}\n"
        
        # Log ra ƒë·ªÉ debug xem ƒë√£ l·∫•y ƒë∆∞·ª£c ch∆∞a
        logger.info(f"Formatted {len(recent_history)} history items for user {user_id}")
        
        return formatted_str

    except Exception as e:
        logger.error(f"Error fetching chat history for user {user_id}: {e}")
        return "Error fetching history."
    
# --- C·∫≠p nh·∫≠t h√†m ask_chatbot ---
def ask_chatbot(query: str, user_id: str = None):
    """
    Ch·∫°y pipeline RAG c√≥ t√≠ch h·ª£p l·ªãch s·ª≠ chat.
    """
    logger.info(f"========= Query M·ªõi =========\nUser ID: {user_id}\nQuery G·ªëc: {query}\n")
    
    # 1. L·∫•y v√† format l·ªãch s·ª≠ chat (M·ªöI)
    chat_history_str = format_chat_history(user_id)
    logger.info(f"Chat History Context:\n{chat_history_str}")

    # 2. Translate
    english_query = translate_query_to_english(query)
    
    # 3. Extract
    filters = extract_filters(english_query)
    logger.info(f"\n[PHASE 2] Extracted Filters:\n{filters.model_dump_json(indent=2, exclude_none=True)}")
    
    # 4. Retrieve
    retrieved_docs = search_scholarships(english_query, filters)
    
    # 5. Generate (Truy·ªÅn th√™m history)
    final_answer_obj = generate_answer(query, retrieved_docs, chat_history_str)
    
    # --- K·∫æT QU·∫¢ ---
    logger.info("\n--- ü§ñ Chatbot Tr·∫£ l·ªùi ---")
    logger.info(final_answer_obj.answer)
    logger.info("\n--- üîë T√™n h·ªçc b·ªïng ---")
    logger.info(f"{final_answer_obj.scholarship_names}") 
    logger.info("\n===============================")
    
    # Tr·∫£ v·ªÅ object ƒë·ªÉ Route s·ª≠ d·ª•ng
    return final_answer_obj

if __name__ == "__main__":
    warnings.filterwarnings("ignore")
    
    # --- Test Case 1 (Ti·∫øng Vi·ªát) ---
    query1 = "T√¥i mu·ªën t√¨m h·ªçc b·ªïng to√†n ph·∫ßn th·∫°c sƒ© ng√†nh khoa h·ªçc d·ªØ li·ªáu ·ªü ch√¢u √¢u, t√¥i c√≥ gpa cao v√† k·ªπ nƒÉng l√£nh ƒë·∫°o t·ªët"
    ask_chatbot(query1)
    
    # --- Test Case 2 (Ti·∫øng Anh) ---
    query2 = "I want to find a full scholarship for a Master‚Äôs program in Data Science in Europe. I have a high GPA and strong leadership skills."
    ask_chatbot(query2)

    # --- (TH√äM D√íNG N√ÄY) ---
    # B·∫£o b·ªô ƒë·ªám x·∫£ log v√†o file tr∆∞·ªõc khi script tho√°t.
    logging.shutdown()